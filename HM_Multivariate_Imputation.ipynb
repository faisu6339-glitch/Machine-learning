{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMydVlN+S7zrssIK7Lu9Lpk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/faisu6339-glitch/Machine-learning/blob/main/HM_Multivariate_Imputation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cddee2de"
      },
      "source": [
        "## Multivariate Imputation by Chained Equations (MICE)\n",
        "\n",
        "Multivariate Imputation by Chained Equations (MICE), also known as 'Fully Conditional Specification' (FCS), is a powerful and flexible method for handling missing data. Here's a breakdown of how it works and why it's popular:\n",
        "\n",
        "### How MICE Works:\n",
        "\n",
        "MICE imputes missing values in a dataset by modeling each incomplete variable conditional on the others. It iteratively cycles through the variables, using a regression model to predict the missing values for one variable based on the observed values of all other variables (including previously imputed values).\n",
        "\n",
        "Here are the general steps:\n",
        "\n",
        "1.  **Initialize**: For each variable with missing values, a simple imputation (e.g., mean imputation, random imputation) is performed as a starting point. This initial imputation is temporary.\n",
        "2.  **Iterative Imputation (Chained Equations)**:\n",
        "    *   For each variable `j` that has missing values:\n",
        "        *   The currently imputed values for `j` are set back to missing.\n",
        "        *   A regression model is fit to predict `j` based on all other variables in the dataset (which now include both observed and their currently imputed values). The type of regression model depends on the nature of variable `j` (e.g., linear regression for continuous variables, logistic regression for binary variables).\n",
        "        *   The missing values in `j` are then imputed using predictions from this model.\n",
        "    *   This process is repeated for all variables with missing data, completing one 'cycle' or 'iteration'.\n",
        "3.  **Repeat**: Steps 2 are repeated for a fixed number of iterations (e.g., 5 to 20). The idea is that after several cycles, the imputed values will stabilize and reflect the relationships within the data more accurately.\n",
        "4.  **Generate Multiple Imputations**: Instead of just one set of imputed values, MICE generates multiple complete datasets (typically 5 to 10). Each complete dataset is created by running the MICE procedure with a different random seed or by drawing imputed values from the predictive distribution of the regression model. This accounts for the uncertainty introduced by imputation.\n",
        "5.  **Analyze and Pool**: Each of the complete datasets is analyzed separately using standard statistical methods. Finally, the results from these separate analyses are combined (pooled) using Rubin's rules to produce a single set of valid statistical inferences that account for imputation uncertainty.\n",
        "\n",
        "### Key Advantages of MICE:\n",
        "\n",
        "*   **Flexibility**: It can handle different types of variables (continuous, binary, categorical) by using appropriate regression models for each.\n",
        "*   **Maintains Relationships**: By modeling variables conditional on each other, MICE preserves the relationships between variables, which is crucial for accurate statistical analysis.\n",
        "*   **Accounts for Uncertainty**: Generating multiple imputations and pooling results provides more accurate standard errors and confidence intervals than single imputation methods, as it incorporates the uncertainty due to missingness.\n",
        "*   **Robustness**: It is generally robust to various missing data mechanisms, particularly 'Missing At Random' (MAR).\n",
        "\n",
        "### When to Use MICE:\n",
        "\n",
        "MICE is a good choice when you have multivariate missing data and you suspect that the missingness is 'Missing At Random' (MAR), meaning the probability of missingness depends only on observed data, not on the missing data itself.\n",
        "\n",
        "It's a widely used and recommended method for imputation in many fields, including social sciences, health research, and machine learning."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import IterativeImputer\n"
      ],
      "metadata": {
        "id": "8nzVtFpp-2Ey"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame({\n",
        "    'Age': [25, np.nan, 35, 40],\n",
        "    'Income': [30000, 50000, np.nan, 70000],\n",
        "    'Experience': [2, 6, 10, np.nan]\n",
        "})\n",
        "\n",
        "imputer = IterativeImputer(max_iter=10, random_state=42)\n",
        "df_imputed = pd.DataFrame(imputer.fit_transform(df), columns=df.columns)\n",
        "\n",
        "print(df_imputed)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UIp4ef3h-1yj",
        "outputId": "dff94453-89de-4497-cd30-2fac117cff79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         Age        Income  Experience\n",
            "0  25.000000  30000.000000    2.000000\n",
            "1  33.333333  50000.000000    6.000000\n",
            "2  35.000000  50000.007035   10.000000\n",
            "3  40.000000  70000.000000   13.943545\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "imputer_train_test = IterativeImputer(max_iter=10, random_state=42)\n",
        "X_train_imputed = imputer_train_test.fit_transform(X_train)\n",
        "X_test_imputed = imputer_train_test.transform(X_test)\n",
        "\n",
        "print(\"X_train_imputed shape:\", X_train_imputed.shape)\n",
        "print(\"X_test_imputed shape:\", X_test_imputed.shape)\n",
        "print(\"\\nX_train_imputed:\\n\", pd.DataFrame(X_train_imputed, columns=X_train.columns))\n",
        "print(\"\\nX_test_imputed:\\n\", pd.DataFrame(X_test_imputed, columns=X_test.columns))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mR9JAAyF-5DL",
        "outputId": "2b9ba119-aa0b-4fca-9086-297e2b02c468"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train_imputed shape: (2, 3)\n",
            "X_test_imputed shape: (2, 3)\n",
            "\n",
            "X_train_imputed:\n",
            "     Age   Income  Experience\n",
            "0  25.0  30000.0         2.0\n",
            "1  35.0  30000.0        10.0\n",
            "\n",
            "X_test_imputed:\n",
            "     Age   Income  Experience\n",
            "0  30.0  50000.0         6.0\n",
            "1  40.0  70000.0        14.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zXYiju8P_CTe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ce9bd8f"
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4b382844",
        "outputId": "49a014e5-236a-4586-a3a2-dfdf26344e10"
      },
      "source": [
        "# Split the DataFrame into training and testing sets\n",
        "X_train, X_test = train_test_split(df, test_size=0.3, random_state=42)\n",
        "\n",
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"X_test shape:\", X_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape: (2, 3)\n",
            "X_test shape: (2, 3)\n"
          ]
        }
      ]
    }
  ]
}